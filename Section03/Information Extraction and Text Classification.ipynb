{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using inbuilt NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleNE():\n",
    "    sent = nltk.corpus.treebank.tagged_sents()[0]\n",
    "    print(nltk.ne_chunk(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleNE2():\n",
    "    sent = nltk.corpus.treebank.tagged_sents()[0]\n",
    "    print(nltk.ne_chunk(sent, binary=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Pierre/NNP)\n",
      "  (ORGANIZATION Vinken/NNP)\n",
      "  ,/,\n",
      "  61/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ,/,\n",
      "  will/MD\n",
      "  join/VB\n",
      "  the/DT\n",
      "  board/NN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  nonexecutive/JJ\n",
      "  director/NN\n",
      "  Nov./NNP\n",
      "  29/CD\n",
      "  ./.)\n",
      "(S\n",
      "  (NE Pierre/NNP Vinken/NNP)\n",
      "  ,/,\n",
      "  61/CD\n",
      "  years/NNS\n",
      "  old/JJ\n",
      "  ,/,\n",
      "  will/MD\n",
      "  join/VB\n",
      "  the/DT\n",
      "  board/NN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  nonexecutive/JJ\n",
      "  director/NN\n",
      "  Nov./NNP\n",
      "  29/CD\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sampleNE()\n",
    "    sampleNE2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, inversing, and using dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningDictionary():\n",
    "    def __init__(self, sentence):\n",
    "        self.words = nltk.word_tokenize(sentence)\n",
    "        self.tagged = nltk.pos_tag(self.words)\n",
    "        self.buildDictionary()\n",
    "        self.buildReverseDictionary()\n",
    "\n",
    "    def buildDictionary(self):\n",
    "        self.dictionary = {}\n",
    "        for (word, pos) in self.tagged:\n",
    "            self.dictionary[word] = pos\n",
    "\n",
    "    def buildReverseDictionary(self):\n",
    "        self.rdictionary = {}\n",
    "        for key in self.dictionary.keys():\n",
    "            value = self.dictionary[key]\n",
    "            if value not in self.rdictionary:\n",
    "                self.rdictionary[value] = [key]\n",
    "            else:\n",
    "                self.rdictionary[value].append(key)\n",
    "\n",
    "    def isWordPresent(self, word):\n",
    "        return 'Yes' if word in self.dictionary else 'No'\n",
    "\n",
    "\n",
    "    def getPOSForWord(self, word):\n",
    "        return self.dictionary[word] if word in self.dictionary else None\n",
    "\n",
    "    def getWordsForPOS(self, pos):\n",
    "        return self.rdictionary[pos] if pos in self.rdictionary else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"All the flights got delayed due to bad weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = LearningDictionary(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"chair\", \"flights\", \"delayed\", \"pencil\", \"weather\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [\"NN\", \"VBS\", \"NNS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'chair' present in dictionary ? : 'No'\n",
      "Is 'flights' present in dictionary ? : 'Yes'\n",
      "Is 'delayed' present in dictionary ? : 'Yes'\n",
      "Is 'pencil' present in dictionary ? : 'No'\n",
      "Is 'weather' present in dictionary ? : 'Yes'\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    status = learning.isWordPresent(word)\n",
    "    print(\"Is '{}' present in dictionary ? : '{}'\".format(word, status))\n",
    "    if status is True:\n",
    "        print(\"\\tPOS For '{}' is '{}'\".format(word, learning.getPOSForWord(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS 'NN' has '['weather']' words\n",
      "POS 'VBS' has 'None' words\n",
      "POS 'NNS' has '['flights']' words\n"
     ]
    }
   ],
   "source": [
    "for pword in pos:\n",
    "    print(\"POS '{}' has '{}' words\".format(pword, learning.getWordsForPOS(pword)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampledata = [\n",
    "    ('KA-01-F 1034 A', 'rtc'),\n",
    "    ('KA-02-F 1030 B', 'rtc'),\n",
    "    ('KA-03-FA 1200 C', 'rtc'),\n",
    "    ('KA-01-G 0001 A', 'gov'),\n",
    "    ('KA-02-G 1004 A', 'gov'),\n",
    "    ('KA-03-G 0204 A', 'gov'),\n",
    "    ('KA-04-G 9230 A', 'gov'),\n",
    "    ('KA-27 1290', 'oth')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sampledata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = [\n",
    "    'KA-01-G 0109',\n",
    "    'KA-02-F 9020 AC',\n",
    "    'KA-02-FA 0801',\n",
    "    'KA-01 9129'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnSimpleFeatures():\n",
    "    def vehicleNumberFeature(vnumber):\n",
    "        return {'vehicle_class': vnumber[6]}\n",
    "    featuresets = [(vehicleNumberFeature(vn), cls) for (vn, cls) in sampledata]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(featuresets)\n",
    "    for num in testdata:\n",
    "        feature = vehicleNumberFeature(num)\n",
    "        print(\"(simple) %s is of type %s\" %(num, classifier.classify(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnFeatures():\n",
    "    def vehicleNumberFeature(vnumber):\n",
    "        return {\n",
    "            'vehicle_class': vnumber[6],\n",
    "            'vehicle_prev': vnumber[5]\n",
    "        }\n",
    "    featuresets = [(vehicleNumberFeature(vn), cls) for (vn, cls) in sampledata]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(featuresets)\n",
    "    for num in testdata:\n",
    "        feature = vehicleNumberFeature(num)\n",
    "        print(\"(dual) %s is of type %s\" %(num, classifier.classify(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(simple) KA-01-G 0109 is of type gov\n",
      "(simple) KA-02-F 9020 AC is of type rtc\n",
      "(simple) KA-02-FA 0801 is of type rtc\n",
      "(simple) KA-01 9129 is of type gov\n",
      "(dual) KA-01-G 0109 is of type gov\n",
      "(dual) KA-02-F 9020 AC is of type rtc\n",
      "(dual) KA-02-FA 0801 is of type rtc\n",
      "(dual) KA-01 9129 is of type oth\n"
     ]
    }
   ],
   "source": [
    "learnSimpleFeatures()\n",
    "learnFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting sentences using classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtractor(words, i):\n",
    "    return ({'current-word': words[i], 'next-is-upper': words[i+1][0].isupper()}, words[i+1][0].isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesets(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    featuresets = [featureExtractor(words, i) for i in range(1, len(words) - 1) if words[i] == '.']\n",
    "    return featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentTextAndPrintSentences(data):\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for i in range(0, len(words) - 1):\n",
    "        if words[i] == '.':\n",
    "            if classifier.classify(featureExtractor(words, i)[0]) == True:\n",
    "                print(\".\")\n",
    "            else:\n",
    "                print(words[i], end='')\n",
    "        else:\n",
    "            print(\"{} \".format(words[i]), end='')\n",
    "    print(words[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = \"India, officially the Republic of India (Bhārat Gaṇarājya),[e] is a country in South Asia. it is the seventh-largest country by area, the second-most populous country (with over 1.2 billion people), and the most populous democracy in the world. It is bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast. It shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the northeast; and Myanmar (Burma) and Bangladesh to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives. India's Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\n",
    "testdata = \"The Indian subcontinent was home to the urban Indus Valley Civilisation of the 3rd millennium BCE. In the following millennium, the oldest scriptures associated with Hinduism began to be composed. Social stratification, based on caste, emerged in the first millennium BCE, and Buddhism and Jainism arose. Early political consolidations took place under the Maurya and Gupta empires; the later peninsular Middle Kingdoms influenced cultures as far as southeast Asia. In the medieval era, Judaism, Zoroastrianism, Christianity, and Islam arrived, and Sikhism emerged, all adding to the region's diverse culture. Much of the north fell to the Delhi sultanate; the south was united under the Vijayanagara Empire. The economy expanded in the 17th century in the Mughal Empire. In the mid-18th century, the subcontinent came under British East India Company rule, and in the mid-19th under British crown rule. A nationalist movement emerged in the late 19th century, which later, under Mahatma Gandhi, was noted for nonviolent resistance and led to India's independence in 1947.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = getFeaturesets(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(traindataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian subcontinent was home to the urban Indus Valley Civilisation of the 3rd millennium BCE .\n",
      "In the following millennium , the oldest scriptures associated with Hinduism began to be composed .\n",
      "Social stratification , based on caste , emerged in the first millennium BCE , and Buddhism and Jainism arose .\n",
      "Early political consolidations took place under the Maurya and Gupta empires ; the later peninsular Middle Kingdoms influenced cultures as far as southeast Asia .\n",
      "In the medieval era , Judaism , Zoroastrianism , Christianity , and Islam arrived , and Sikhism emerged , all adding to the region 's diverse culture .\n",
      "Much of the north fell to the Delhi sultanate ; the south was united under the Vijayanagara Empire .\n",
      "The economy expanded in the 17th century in the Mughal Empire .\n",
      "In the mid-18th century , the subcontinent came under British East India Company rule , and in the mid-19th under British crown rule .\n",
      "A nationalist movement emerged in the late 19th century , which later , under Mahatma Gandhi , was noted for nonviolent resistance and led to India 's independence in 1947 .\n"
     ]
    }
   ],
   "source": [
    "segmentTextAndPrintSentences(testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a POS tagger with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"What is your address when you're in Bangalore?\",\n",
    "    \"the president's address on the state of the economy.\",\n",
    "    \"He addressed his remarks to the lawyers in the audience.\",\n",
    "    \"In order to address an assembly, we should be ready\",\n",
    "    \"He laughed inwardly at the scene.\",\n",
    "    \"After all the advance publicity, the prizefight turned out to be a laugh.\",\n",
    "    \"We can learn to laugh a little at even our most serious foibles.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceWords():\n",
    "    sentwords = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        sentwords.append(words)\n",
    "    return sentwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noContextTagger():\n",
    "    tagger = nltk.UnigramTagger(getSentenceWords())\n",
    "    print(tagger.tag('the little remarks towards assembly are laughable'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def withContextTagger():\n",
    "    def wordFeatures(words, wordPosInSentence):\n",
    "        endFeatures = {\n",
    "            'last(1)': words[wordPosInSentence][-1],\n",
    "            'last(2)': words[wordPosInSentence][-2:],\n",
    "            'last(3)': words[wordPosInSentence][-3:],\n",
    "        }\n",
    "        if wordPosInSentence > 1:\n",
    "            endFeatures['prev'] = words[wordPosInSentence - 1]\n",
    "        else:\n",
    "            endFeatures['prev'] = '|NONE|'\n",
    "        return endFeatures\n",
    "    allsentences = getSentenceWords()\n",
    "    featureddata = []\n",
    "    for sentence in allsentences:\n",
    "        untaggedSentence = nltk.tag.untag(sentence)\n",
    "        featuredsentence = [(wordFeatures(untaggedSentence, index), tag) for index, (word, tag) in enumerate(sentence)]\n",
    "        featureddata.extend(featuredsentence)\n",
    "    breakup = int(len(featureddata) * 0.5)\n",
    "    traindata = featureddata[breakup:]\n",
    "    testdata = featureddata[:breakup]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(traindata)\n",
    "    print(\"Accuracy of the classifier : {}\".format(nltk.classify.accuracy(classifier, testdata)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('little', 'JJ'), ('remarks', 'NNS'), ('towards', None), ('assembly', 'NN'), ('are', None), ('laughable', None)]\n",
      "Accuracy of the classifier : 0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "noContextTagger()\n",
    "withContextTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
