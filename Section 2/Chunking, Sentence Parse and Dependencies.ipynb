{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the built-in chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Lalbagh Botanical Gardens is a well known botanical garden in Bengaluru, India.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Lalbagh/NNP)\n",
      "  (PERSON Botanical/NNP Gardens/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  well/RB\n",
      "  known/VBN\n",
      "  botanical/JJ\n",
      "  garden/NN\n",
      "  in/IN\n",
      "  (GPE Bengaluru/NNP)\n",
      "  ,/,\n",
      "  (GPE India/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    chunks = nltk.ne_chunk(tags)\n",
    "    print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own simple chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"Ravi is the CEO of a Company. He is very powerful public speaker also.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = '\\n'.join([\n",
    "    'NP: {<DT>*<NNP>}',\n",
    "    'NP: {<JJ>*<NN>}',\n",
    "    'NP: {<NNP>+}',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Ravi/NNP)\n",
      "  is/VBZ\n",
      "  (NP the/DT CEO/NNP)\n",
      "  of/IN\n",
      "  (NP a/DT Company/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  He/PRP\n",
      "  is/VBZ\n",
      "  very/RB\n",
      "  (NP powerful/JJ public/JJ speaker/NN)\n",
      "  also/RB\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    chunkparser = nltk.RegexpParser(grammar)\n",
    "    result = chunkparser.parse(tags)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a chunker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mySimpleChunker():\n",
    "    grammar = 'NP: {<NNP>+}'\n",
    "    return nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_nothing(data):\n",
    "    cp = nltk.RegexpParser(\"\")\n",
    "    print(cp.evaluate(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_mysimplechunker(data):\n",
    "    schunker = mySimpleChunker()\n",
    "    print(schunker.evaluate(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    " conll2000.chunked_sents('test.txt', chunk_types=['NP']),\n",
    " treebank_chunk.chunked_sents()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  38.6%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  48.2%%\n",
      "    Precision:     71.1%%\n",
      "    Recall:        17.2%%\n",
      "    F-Measure:     27.7%%\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  45.0%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  50.7%%\n",
      "    Precision:     51.9%%\n",
      "    Recall:         8.8%%\n",
      "    F-Measure:     15.1%%\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    test_nothing(dataset[:50])\n",
    "    test_mysimplechunker(dataset[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing recursive descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RDParserExample(grammar, textlist):\n",
    "    parser = nltk.parse.RecursiveDescentParser(grammar)\n",
    "    for text in textlist:\n",
    "        sentence = nltk.word_tokenize(text)\n",
    "        for tree in parser.parse(sentence):\n",
    "            print(tree)\n",
    "            tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> NNP VBZ\n",
    "VP -> IN NNP | DT NN IN NNP\n",
    "NNP -> 'Tajmahal' | 'Agra' | 'Bangalore' | 'Karnataka'\n",
    "VBZ -> 'is'\n",
    "IN -> 'in' | 'of'\n",
    "DT -> 'the'\n",
    "NN -> 'capital'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Tajmahal is in Agra\",\n",
    "    \"Bangalore is the capital of Karnataka\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NNP Tajmahal) (VBZ is)) (VP (IN in) (NNP Agra)))\n",
      "(S\n",
      "  (NP (NNP Bangalore) (VBZ is))\n",
      "  (VP (DT the) (NN capital) (IN of) (NNP Karnataka)))\n"
     ]
    }
   ],
   "source": [
    "RDParserExample(grammar, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing shift-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SRParserExample(grammar, textlist):\n",
    "    parser = nltk.parse.ShiftReduceParser(grammar)\n",
    "    for text in textlist:\n",
    "        sentence = nltk.word_tokenize(text)\n",
    "        for tree in parser.parse(sentence):\n",
    "            print(tree)\n",
    "            tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Tajmahal is in Agra\",\n",
    "    \"Bangalore is the capital of Karnataka\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> NNP VBZ\n",
    "VP -> IN NNP | DT NN IN NNP\n",
    "NNP -> 'Tajmahal' | 'Agra' | 'Bangalore' | 'Karnataka'\n",
    "VBZ -> 'is'\n",
    "IN -> 'in' | 'of'\n",
    "DT -> 'the'\n",
    "NN -> 'capital'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NNP Tajmahal) (VBZ is)) (VP (IN in) (NNP Agra)))\n"
     ]
    }
   ],
   "source": [
    "SRParserExample(grammar, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dependency grammar and projective dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = nltk.grammar.DependencyGrammar.fromstring(\"\"\"\n",
    "'savings' -> 'small'\n",
    "'yield' -> 'savings'\n",
    "'gains' -> 'large'\n",
    "'yield' -> 'gains'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'small savings yield large gains'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = nltk.parse.ProjectiveDependencyParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(yield (savings small) (gains large))\n"
     ]
    }
   ],
   "source": [
    "for t in sorted(dp.parse(sentence.split())):\n",
    "    print(t)\n",
    "    t.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing a chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.grammar import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.chart import ChartParser, BU_LC_STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> T1 T4\n",
    "T1 -> NNP VBZ\n",
    "T2 -> DT NN\n",
    "T3 -> IN NNP\n",
    "T4 -> T3 | T2 T3\n",
    "NNP -> 'Tajmahal' | 'Agra' | 'Bangalore' | 'Karnataka'\n",
    "VBZ -> 'is'\n",
    "IN -> 'in' | 'of'\n",
    "DT -> 'the'\n",
    "NN -> 'capital'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cp = ChartParser(grammar, BU_LC_STRATEGY, trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = \"Bangalore is the capital of Karnataka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Bangal.  is  . the  .capita.  of  .Karnat.|\n",
      "|[------]      .      .      .      .      .| [0:1] 'Bangalore'\n",
      "|.      [------]      .      .      .      .| [1:2] 'is'\n",
      "|.      .      [------]      .      .      .| [2:3] 'the'\n",
      "|.      .      .      [------]      .      .| [3:4] 'capital'\n",
      "|.      .      .      .      [------]      .| [4:5] 'of'\n",
      "|.      .      .      .      .      [------]| [5:6] 'Karnataka'\n",
      "|[------]      .      .      .      .      .| [0:1] NNP -> 'Bangalore' *\n",
      "|[------>      .      .      .      .      .| [0:1] T1 -> NNP * VBZ\n",
      "|.      [------]      .      .      .      .| [1:2] VBZ -> 'is' *\n",
      "|[-------------]      .      .      .      .| [0:2] T1 -> NNP VBZ *\n",
      "|[------------->      .      .      .      .| [0:2] S  -> T1 * T4\n",
      "|.      .      [------]      .      .      .| [2:3] DT -> 'the' *\n",
      "|.      .      [------>      .      .      .| [2:3] T2 -> DT * NN\n",
      "|.      .      .      [------]      .      .| [3:4] NN -> 'capital' *\n",
      "|.      .      [-------------]      .      .| [2:4] T2 -> DT NN *\n",
      "|.      .      [------------->      .      .| [2:4] T4 -> T2 * T3\n",
      "|.      .      .      .      [------]      .| [4:5] IN -> 'of' *\n",
      "|.      .      .      .      [------>      .| [4:5] T3 -> IN * NNP\n",
      "|.      .      .      .      .      [------]| [5:6] NNP -> 'Karnataka' *\n",
      "|.      .      .      .      .      [------>| [5:6] T1 -> NNP * VBZ\n",
      "|.      .      .      .      [-------------]| [4:6] T3 -> IN NNP *\n",
      "|.      .      .      .      [-------------]| [4:6] T4 -> T3 *\n",
      "|.      .      [---------------------------]| [2:6] T4 -> T2 T3 *\n",
      "|[=========================================]| [0:6] S  -> T1 T4 *\n"
     ]
    }
   ],
   "source": [
    "chart = cp.chart_parse(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parses = list(chart.parses(grammar.start()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Edges : 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Edges :\", len(chart.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (T1 (NNP Bangalore) (VBZ is))\n",
      "  (T4 (T2 (DT the) (NN capital)) (T3 (IN of) (NNP Karnataka))))\n"
     ]
    }
   ],
   "source": [
    "for tree in parses: print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
